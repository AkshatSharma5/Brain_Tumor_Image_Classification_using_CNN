{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nIMJd1jJwINa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30ca6b4-0b16-457f-82b0-533f01b627cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive outputs -> /content/drive/MyDrive/BTP_colab\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/BTP_colab\"\n",
        "import os\n",
        "for d in [\"models\",\"logs\",\"reports\",\"reports/figures\"]:\n",
        "    os.makedirs(f\"{DRIVE_ROOT}/{d}\", exist_ok=True)\n",
        "print(\"Drive outputs ->\", DRIVE_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf BTP\n",
        "!mkdir -p BTP/src/data BTP/src/models BTP/src/xai BTP/models BTP/logs BTP/reports/figures BTP/data/raw BTP/data/processed\n",
        "%cd /content/BTP\n",
        "!touch src/__init__.py src/data/__init__.py src/models/__init__.py src/xai/__init__.py\n",
        "import os\n",
        "print(\"Project root:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FVd4yerw4MH",
        "outputId": "1f13d1d4-4c58-4070-8032-01797f6e87b9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/BTP\n",
            "Project root: /content/BTP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.yaml\n",
        "data:\n",
        "  raw_dir: \"data/raw\"\n",
        "  processed_dir: \"data/processed\"\n",
        "  img_size: 224\n",
        "  classes: [\"glioma\",\"meningioma\",\"pituitary\",\"no_tumor\"]\n",
        "\n",
        "train:\n",
        "  batch_size: 32\n",
        "  epochs: 14          # total epochs\n",
        "  warmup_epochs: 4    # head-only training\n",
        "  learning_rate: 0.0001\n",
        "  finetune_lr: 0.00001\n",
        "  model_name: \"resnet50\"\n",
        "  freeze_base: true\n",
        "  unfreeze_block: \"layer4\"   # options: layer4 or all\n",
        "  max_images: 0              # 0 or null = use all images\n",
        "\n",
        "callbacks:\n",
        "  early_stopping: true\n",
        "  patience: 5\n",
        "\n",
        "paths:\n",
        "  models_dir: \"/content/drive/MyDrive/BTP_colab/models\"\n",
        "  logs_dir: \"/content/drive/MyDrive/BTP_colab/logs\"\n",
        "  reports_dir: \"/content/drive/MyDrive/BTP_colab/reports\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDK3E_1Fw_6u",
        "outputId": "060aa6f2-1eec-4bbf-f736-18059f115ec6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install albumentations seaborn pyyaml grad-cam\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n"
      ],
      "metadata": {
        "id": "YgtEbQebxfN-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print(\"Click 'Choose files' and select kaggle.json (Kaggle Account > Create New API Token)\")\n",
        "_ = files.upload()\n",
        "\n",
        "!pip -q install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "%cd /content/BTP/data/raw\n",
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset -q\n",
        "!unzip -q brain-tumor-mri-dataset.zip\n",
        "\n",
        "# Move Training/Testing up if nested\n",
        "import os, glob, shutil\n",
        "for name in ['Training','Testing']:\n",
        "    hits = [p for p in glob.glob('**/'+name, recursive=True) if os.path.isdir(p)]\n",
        "    if hits and not os.path.isdir(name):\n",
        "        shutil.move(hits[0], name)\n",
        "print(\"Has Training:\", os.path.isdir(\"Training\"), \"Has Testing:\", os.path.isdir(\"Testing\"))\n",
        "%cd /content/BTP\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Dc42MMDwxgbl",
        "outputId": "38b14c05-278a-4e98-8876-367a68609e97"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click 'Choose files' and select kaggle.json (Kaggle Account > Create New API Token)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-124220c2-965e-477a-b040-6e38c377b551\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-124220c2-965e-477a-b040-6e38c377b551\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "/content/BTP/data/raw\n",
            "Dataset URL: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
            "License(s): CC0-1.0\n",
            "Has Training: True Has Testing: True\n",
            "/content/BTP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/data/generator.py\n",
        "import os, yaml\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "IMG = cfg['data']['img_size']\n",
        "def get_generators(batch_size):\n",
        "    proc = cfg['data']['processed_dir']\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                       rotation_range=15,\n",
        "                                       width_shift_range=0.1,\n",
        "                                       height_shift_range=0.1,\n",
        "                                       zoom_range=0.1,\n",
        "                                       horizontal_flip=True,\n",
        "                                       fill_mode='nearest')\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    train_gen = train_datagen.flow_from_directory(os.path.join(proc,'train'),\n",
        "                                                  target_size=(IMG,IMG),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical', shuffle=True)\n",
        "    val_gen = test_datagen.flow_from_directory(os.path.join(proc,'val'),\n",
        "                                               target_size=(IMG,IMG),\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='categorical', shuffle=False)\n",
        "    test_gen = test_datagen.flow_from_directory(os.path.join(proc,'test'),\n",
        "                                                target_size=(IMG,IMG),\n",
        "                                                batch_size=1,\n",
        "                                                class_mode='categorical', shuffle=False)\n",
        "    return train_gen, val_gen, test_gen\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVxIqh8axhKj",
        "outputId": "7b2baf22-f1d7-42fd-ec73-0bb68754beec"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/data/generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/models/build_model.py\n",
        "import yaml, tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "def build_model():\n",
        "    img_size = cfg['data']['img_size']\n",
        "    n_classes = len(cfg['data']['classes'])\n",
        "    backbone = cfg['train']['model_name']\n",
        "    freeze_base = cfg['train'].get('freeze_base', True)\n",
        "    if backbone.lower() == 'resnet50':\n",
        "        base = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size,img_size,3))\n",
        "        last_conv = 'conv5_block3_out'\n",
        "    elif backbone.lower().startswith('efficient'):\n",
        "        base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_size,img_size,3))\n",
        "        last_conv = 'top_activation'\n",
        "    else:\n",
        "        raise ValueError(\"Unknown backbone\")\n",
        "    if freeze_base:\n",
        "        for layer in base.layers: layer.trainable = False\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    out = Dense(n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base.input, outputs=out)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(cfg['train']['learning_rate']),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model, last_conv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVVepqcIxhM5",
        "outputId": "3d5f344a-ba26-493d-cd86-02ee9a1c461a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/models/build_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils.py\n",
        "import os, yaml, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np, seaborn as sns\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "def save_plot_history(history, out_path):\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(history.history['accuracy'], label='train_acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "    plt.title('Accuracy'); plt.legend(); plt.savefig(out_path+\"_acc.png\"); plt.close()\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(history.history['loss'], label='train_loss')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss')\n",
        "    plt.title('Loss'); plt.legend(); plt.savefig(out_path+\"_loss.png\"); plt.close()\n",
        "def save_confusion(y_true, y_pred, labels, out_path):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
        "    plt.ylabel('True'); plt.xlabel('Predicted'); plt.title('Confusion Matrix')\n",
        "    plt.savefig(out_path); plt.close()\n",
        "def ensure_reports_dirs():\n",
        "    os.makedirs(cfg['paths']['reports_dir'], exist_ok=True)\n",
        "    os.makedirs(os.path.join(cfg['paths']['reports_dir'],'figures'), exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHSlTEToxhQU",
        "outputId": "60bc38bd-8acb-44c7-8fc6-a35c14a83855"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/train.py\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import yaml, tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "from src.data.generator import get_generators\n",
        "from src.models.build_model import build_model\n",
        "from src.utils import save_plot_history, ensure_reports_dirs\n",
        "\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "\n",
        "def unfreeze_top(model, which=\"layer4\"):\n",
        "    if which == \"all\":\n",
        "        for l in model.layers:\n",
        "            l.trainable = True\n",
        "    else:\n",
        "        # Unfreeze only top ResNet block if available\n",
        "        for l in model.layers:\n",
        "            if \"conv5_block\" in l.name or \"post_relu\" in l.name:\n",
        "                l.trainable = True\n",
        "\n",
        "def compile_with_lr(model, lr):\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=float(lr)),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "def main():\n",
        "    ensure_reports_dirs()\n",
        "    batch = cfg['train']['batch_size']\n",
        "    epochs = int(cfg['train']['epochs'])\n",
        "    warmup = int(cfg['train']['warmup_epochs'])\n",
        "    model_dir = cfg['paths']['models_dir']\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    train_gen, val_gen, _ = get_generators(batch)\n",
        "    model, last_conv = build_model()\n",
        "\n",
        "    # Phase 1: head-only training\n",
        "    compile_with_lr(model, cfg['train']['learning_rate'])\n",
        "    cb = [\n",
        "        ModelCheckpoint(os.path.join(model_dir,'best_model.h5'), save_best_only=True, monitor='val_loss', verbose=1),\n",
        "        EarlyStopping(patience=cfg['callbacks']['patience'], restore_best_weights=True),\n",
        "        ReduceLROnPlateau(patience=3, factor=0.5, verbose=1),\n",
        "        CSVLogger(os.path.join(cfg['paths']['logs_dir'],'training_log.csv'), append=True)\n",
        "    ]\n",
        "    if warmup > 0:\n",
        "        print(f\"Warmup (frozen base) for {warmup} epochs...\")\n",
        "        model.fit(train_gen, validation_data=val_gen, epochs=warmup, callbacks=cb)\n",
        "\n",
        "    # Phase 2: fine-tune top block (or all) with smaller LR\n",
        "    unfreeze_top(model, cfg['train'].get('unfreeze_block', 'layer4'))\n",
        "    compile_with_lr(model, cfg['train']['finetune_lr'])\n",
        "    remaining = max(0, epochs - warmup)\n",
        "    if remaining > 0:\n",
        "        print(f\"Fine-tuning for {remaining} epochs...\")\n",
        "        model.fit(train_gen, validation_data=val_gen, epochs=remaining, callbacks=cb)\n",
        "\n",
        "    save_plot_history(model.history if hasattr(model, \"history\") else None,\n",
        "                      os.path.join(cfg['paths']['reports_dir'],'train_val'))\n",
        "    print(\"Saved:\", os.path.join(model_dir,'best_model.h5'))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dleTCQXLx0rr",
        "outputId": "fc249997-3785-4c2f-dfb4-f7b4090d050f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/data/preprocess.py\n",
        "import os, yaml, cv2, random\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "RAW = cfg['data']['raw_dir']; PROC = cfg['data']['processed_dir']\n",
        "IMG = cfg['data']['img_size']; CLASSES = cfg['data']['classes']\n",
        "MAX_IMAGES = int(cfg['train'].get('max_images', 0) or 0)\n",
        "def ensure_dirs():\n",
        "    for split in ['train','val','test']:\n",
        "        for c in CLASSES:\n",
        "            os.makedirs(os.path.join(PROC, split, c), exist_ok=True)\n",
        "def files_under(root, classes):\n",
        "    paths, labels = [], []\n",
        "    for c in classes:\n",
        "        for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\"):\n",
        "            for f in glob(os.path.join(root, c, ext)):\n",
        "                paths.append(f); labels.append(c)\n",
        "    return paths, labels\n",
        "def stratified_cap(paths, labels, cap):\n",
        "    if cap <= 0 or cap >= len(paths): return paths, labels\n",
        "    by = {}\n",
        "    for p,l in zip(paths,labels): by.setdefault(l, []).append(p)\n",
        "    total=len(paths); outp=[]; outl=[]; rem=cap\n",
        "    for c, arr in by.items():\n",
        "        random.shuffle(arr); take=round(len(arr)*cap/total); take=min(take,len(arr))\n",
        "        outp+=arr[:take]; outl+=[c]*take; rem-=take\n",
        "    if rem>0:\n",
        "        for c, arr in sorted(by.items(), key=lambda kv: -len(kv[1])):\n",
        "            extra=[p for p in arr if p not in outp]; need=min(rem,len(extra))\n",
        "            outp+=extra[:need]; outl+=[c]*need; rem-=need\n",
        "            if rem<=0: break\n",
        "    idx=list(range(len(outp))); random.shuffle(idx)\n",
        "    return [outp[i] for i in idx], [outl[i] for i in idx]\n",
        "def resize_copy(ps, ls, split):\n",
        "    for p,lab in zip(ps,ls):\n",
        "        img=cv2.imread(p);\n",
        "        if img is None: continue\n",
        "        import numpy as np\n",
        "        img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB); img=cv2.resize(img,(IMG,IMG))\n",
        "        out=os.path.join(PROC,split,lab,os.path.basename(p))\n",
        "        cv2.imwrite(out, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "def main():\n",
        "    random.seed(42); ensure_dirs()\n",
        "    train_root=os.path.join(RAW,\"Training\"); test_root=os.path.join(RAW,\"Testing\")\n",
        "    if not (os.path.isdir(train_root) and os.path.isdir(test_root)):\n",
        "        raise RuntimeError(f\"Expected {train_root} and {test_root}\")\n",
        "    trp,trl=files_under(train_root,CLASSES); tep,tel=files_under(test_root,CLASSES)\n",
        "    allp=trp+tep; alll=trl+tel\n",
        "    if MAX_IMAGES and len(allp)>MAX_IMAGES:\n",
        "        allp, alll = stratified_cap(allp, alll, MAX_IMAGES)\n",
        "    ptv, pte, ltv, lte = train_test_split(allp, alll, test_size=0.10, stratify=alll, random_state=42)\n",
        "    ptr, pva, ltr, lva = train_test_split(ptv, ltv, test_size=0.1111, stratify=ltv, random_state=42)\n",
        "    resize_copy(ptr,ltr,\"train\"); resize_copy(pva,lva,\"val\"); resize_copy(pte,lte,\"test\")\n",
        "    print(f\"Processed -> {PROC} (cap={MAX_IMAGES})\")\n",
        "if __name__==\"__main__\": main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTi2VmwPx0v8",
        "outputId": "c1a0ed38-46f1-4686-df23-45ebf8241c06"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/data/preprocess.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.data.preprocess\n",
        "\n",
        "import os, sys, importlib\n",
        "%cd /content/BTP\n",
        "if \"/content/BTP\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content/BTP\")\n",
        "print(\"Has src?\", os.path.isdir(\"src\"))\n",
        "print(\"Has generator.py?\", os.path.isfile(\"src/data/generator.py\"))\n",
        "importlib.import_module(\"src.data.generator\")\n",
        "print(\"Import OK\")\n",
        "\n",
        "!python -m src.train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XAAg06Ax0zc",
        "outputId": "2f0bbf6f-3ac4-4dd1-8416-f48de7819222"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed -> data/processed (cap=0)\n",
            "/content/BTP\n",
            "Has src? True\n",
            "Has generator.py? True\n",
            "Import OK\n",
            "2025-09-21 10:45:05.353746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758451505.385981   11748 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758451505.395489   11748 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758451505.456549   11748 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758451505.456597   11748 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758451505.456606   11748 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758451505.456612   11748 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Found 4017 images belonging to 4 classes.\n",
            "Found 503 images belonging to 4 classes.\n",
            "Found 503 images belonging to 4 classes.\n",
            "I0000 00:00:1758451514.816945   11748 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Warmup (frozen base) for 4 epochs...\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "Epoch 1/4\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1758451526.324924   11826 service.cc:152] XLA service 0x7b2e18002bb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1758451526.324967   11826 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1758451528.643588   11826 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1758451533.511124   11826 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - accuracy: 0.3293 - loss: 1.4371\n",
            "Epoch 1: val_loss improved from inf to 1.07103, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 556ms/step - accuracy: 0.3294 - loss: 1.4359 - val_accuracy: 0.3638 - val_loss: 1.0710 - learning_rate: 1.0000e-04\n",
            "Epoch 2/4\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.3569 - loss: 1.1516\n",
            "Epoch 2: val_loss improved from 1.07103 to 1.03683, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 455ms/step - accuracy: 0.3570 - loss: 1.1513 - val_accuracy: 0.4334 - val_loss: 1.0368 - learning_rate: 1.0000e-04\n",
            "Epoch 3/4\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.3904 - loss: 1.0912\n",
            "Epoch 3: val_loss improved from 1.03683 to 1.00282, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 442ms/step - accuracy: 0.3907 - loss: 1.0910 - val_accuracy: 0.6223 - val_loss: 1.0028 - learning_rate: 1.0000e-04\n",
            "Epoch 4/4\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.4720 - loss: 1.0421\n",
            "Epoch 4: val_loss improved from 1.00282 to 0.98159, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 452ms/step - accuracy: 0.4721 - loss: 1.0420 - val_accuracy: 0.5447 - val_loss: 0.9816 - learning_rate: 1.0000e-04\n",
            "Fine-tuning for 10 epochs...\n",
            "Epoch 1/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - accuracy: 0.4896 - loss: 1.5803\n",
            "Epoch 1: val_loss did not improve from 0.98159\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 536ms/step - accuracy: 0.4904 - loss: 1.5761 - val_accuracy: 0.3280 - val_loss: 1.5986 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.6691 - loss: 0.7530\n",
            "Epoch 2: val_loss did not improve from 0.98159\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 422ms/step - accuracy: 0.6692 - loss: 0.7528 - val_accuracy: 0.3917 - val_loss: 1.3658 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.7255 - loss: 0.6652\n",
            "Epoch 3: val_loss improved from 0.98159 to 0.66758, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 455ms/step - accuracy: 0.7255 - loss: 0.6652 - val_accuracy: 0.6958 - val_loss: 0.6676 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.7222 - loss: 0.6426\n",
            "Epoch 4: val_loss improved from 0.66758 to 0.59129, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 457ms/step - accuracy: 0.7223 - loss: 0.6424 - val_accuracy: 0.7396 - val_loss: 0.5913 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.7374 - loss: 0.6297\n",
            "Epoch 5: val_loss improved from 0.59129 to 0.51587, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 466ms/step - accuracy: 0.7375 - loss: 0.6295 - val_accuracy: 0.7813 - val_loss: 0.5159 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - accuracy: 0.7894 - loss: 0.5329\n",
            "Epoch 6: val_loss improved from 0.51587 to 0.51102, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 489ms/step - accuracy: 0.7893 - loss: 0.5330 - val_accuracy: 0.7873 - val_loss: 0.5110 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.7553 - loss: 0.5564\n",
            "Epoch 7: val_loss improved from 0.51102 to 0.47262, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 506ms/step - accuracy: 0.7554 - loss: 0.5564 - val_accuracy: 0.8052 - val_loss: 0.4726 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.7751 - loss: 0.5434\n",
            "Epoch 8: val_loss did not improve from 0.47262\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 449ms/step - accuracy: 0.7751 - loss: 0.5434 - val_accuracy: 0.7575 - val_loss: 0.5656 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.7994 - loss: 0.4937\n",
            "Epoch 9: val_loss improved from 0.47262 to 0.43481, saving model to /content/drive/MyDrive/BTP_colab/models/best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 459ms/step - accuracy: 0.7994 - loss: 0.4938 - val_accuracy: 0.8151 - val_loss: 0.4348 - learning_rate: 1.0000e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.8046 - loss: 0.4896\n",
            "Epoch 10: val_loss did not improve from 0.43481\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 421ms/step - accuracy: 0.8045 - loss: 0.4896 - val_accuracy: 0.7853 - val_loss: 0.5412 - learning_rate: 1.0000e-05\n",
            "Saved: /content/drive/MyDrive/BTP_colab/models/best_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/evaluate.py\n",
        "import yaml, os, numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from src.data.generator import get_generators\n",
        "from src.utils import save_confusion, ensure_reports_dirs\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "\n",
        "def main():\n",
        "    ensure_reports_dirs()\n",
        "    _, _, test_gen = get_generators(cfg['train']['batch_size'])\n",
        "    model = load_model(os.path.join(cfg['paths']['models_dir'],'best_model.h5'))\n",
        "    preds = model.predict(test_gen, verbose=1)\n",
        "    y_pred = preds.argmax(axis=1)\n",
        "    y_true = test_gen.classes\n",
        "    idx_to_name = {v:k for k,v in test_gen.class_indices.items()}\n",
        "    labels = sorted(test_gen.class_indices.values())\n",
        "    target_names = [idx_to_name[i] for i in labels]\n",
        "    report = classification_report(y_true, y_pred, labels=labels, target_names=target_names, zero_division=0)\n",
        "    print(report)\n",
        "    with open(os.path.join(cfg['paths']['reports_dir'],'classification_report.txt'),'w') as f:\n",
        "        f.write(report)\n",
        "    save_confusion(y_true, y_pred, target_names, os.path.join(cfg['paths']['reports_dir'],'figures','confusion_matrix.png'))\n",
        "    print(\"Reports saved to\", cfg['paths']['reports_dir'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1PU8bsPxzYu",
        "outputId": "1542e162-e82e-4d00-80ab-4204d7dcb024"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.evaluate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc4_d5l5xzbZ",
        "outputId": "50959d24-3f5e-4f50-cd1c-dabb689bdae5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-21 11:00:59.438691: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758452459.470864   16124 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758452459.480619   16124 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758452459.503918   16124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452459.503950   16124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452459.503955   16124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452459.503962   16124 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Found 4017 images belonging to 4 classes.\n",
            "Found 503 images belonging to 4 classes.\n",
            "Found 503 images belonging to 4 classes.\n",
            "I0000 00:00:1758452466.107422   16124 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1758452512.572537   16203 service.cc:152] XLA service 0x7c127c0040c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1758452512.572578   16203 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1758452513.277444   16203 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1758452515.505582   16203 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      glioma       0.83      0.78      0.81       162\n",
            "  meningioma       0.81      0.75      0.78       165\n",
            "    no_tumor       0.00      0.00      0.00         0\n",
            "   pituitary       0.85      0.97      0.91       176\n",
            "\n",
            "    accuracy                           0.83       503\n",
            "   macro avg       0.62      0.62      0.62       503\n",
            "weighted avg       0.83      0.83      0.83       503\n",
            "\n",
            "Reports saved to /content/drive/MyDrive/BTP_colab/reports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/gradcam.py\n",
        "import numpy as np, tensorflow as tf, cv2, yaml\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model([model.inputs],[model.get_layer(last_conv_layer_name).output, model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None: pred_index = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, pred_index]\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
        "    conv_outputs = conv_outputs[0].numpy()\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]): conv_outputs[..., i] *= pooled_grads[i]\n",
        "    heatmap = np.maximum(np.mean(conv_outputs, axis=-1), 0)\n",
        "    heatmap /= (np.max(heatmap)+1e-8)\n",
        "    return heatmap\n",
        "def overlay_heatmap(original_img, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
        "    hmap = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n",
        "    hmap = np.uint8(255 * hmap); hmap = cv2.applyColorMap(hmap, colormap)\n",
        "    overlay = cv2.addWeighted(cv2.cvtColor(original_img, cv2.COLOR_RGB2BGR), 1-alpha, hmap, alpha, 0)\n",
        "    return cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBVbmXCDxzdv",
        "outputId": "0502dfb3-25af-45fa-dbda-7d2e1a89a2fb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/gradcam.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iszTFOLB8YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/predict.py\n",
        "import sys, yaml, cv2, numpy as np, os\n",
        "from tensorflow.keras.models import load_model\n",
        "from src.gradcam import make_gradcam_heatmap, overlay_heatmap\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "MODEL_PATH = os.path.join(cfg['paths']['models_dir'],'best_model.h5')\n",
        "def load_and_preprocess(path):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None: raise FileNotFoundError(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    sz = cfg['data']['img_size']\n",
        "    img_res = cv2.resize(img, (sz, sz))\n",
        "    img_norm = img_res.astype('float32')/255.0\n",
        "    return img_res, np.expand_dims(img_norm, axis=0)\n",
        "def predict_and_explain(path):\n",
        "    img_orig, x = load_and_preprocess(path)\n",
        "    model = load_model(MODEL_PATH)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    idx = int(np.argmax(preds)); classes = cfg['data']['classes']\n",
        "    last_conv = 'conv5_block3_out' if cfg['train']['model_name']=='resnet50' else 'top_activation'\n",
        "    heatmap = make_gradcam_heatmap(x, model, last_conv, pred_index=idx)\n",
        "    overlay = overlay_heatmap(img_orig, heatmap)\n",
        "    outdir = os.path.join(cfg['paths']['reports_dir'],'figures'); os.makedirs(outdir, exist_ok=True)\n",
        "    fname = os.path.join(outdir, f\"gradcam_{classes[idx]}.png\")\n",
        "    cv2.imwrite(fname, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
        "    print({\"predicted\": classes[idx], \"confidence\": float(preds[idx]), \"saved\": fname})\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) < 2:\n",
        "        print(\"Usage: !python -m src.predict path/to/image.jpg\"); sys.exit(1)\n",
        "    predict_and_explain(sys.argv[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWdlnP_KxzhU",
        "outputId": "9e2fc72b-27cf-410a-9b9c-4f1386ed8763"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "test_imgs = glob.glob('data/processed/test/*/*.jpg')\n",
        "print(\"Test images:\", len(test_imgs))\n",
        "if test_imgs:\n",
        "    demo = test_imgs[0]\n",
        "    !python -m src.predict \"{demo}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPyAYVBs1OJF",
        "outputId": "ccb88748-630d-4f3e-deb1-2573103dbd08"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test images: 503\n",
            "2025-09-21 11:02:02.400864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758452522.434754   16490 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758452522.444489   16490 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758452522.467793   16490 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452522.467824   16490 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452522.467832   16490 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452522.467839   16490 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "I0000 00:00:1758452527.251835   16490 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1758452532.080589   16530 service.cc:152] XLA service 0x7c1698002fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1758452532.080624   16530 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1758452534.696950   16530 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1758452538.748661   16530 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: [['input_layer']]\n",
            "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
            "  warnings.warn(msg)\n",
            "{'predicted': 'glioma', 'confidence': 0.6966471076011658, 'saved': '/content/drive/MyDrive/BTP_colab/reports/figures/gradcam_glioma.png'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/drive/MyDrive/BTP_colab/models\n",
        "!ls -lah /content/drive/MyDrive/BTP_colab/reports\n",
        "!ls -lah /content/drive/MyDrive/BTP_colab/reports/figures\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAikEo6L1OOd",
        "outputId": "d9174e7b-e5e0-406d-a495-70d5ed8925af"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 211M\n",
            "-rw------- 1 root root 211M Sep 21 10:59 best_model.h5\n",
            "total 50K\n",
            "-rw------- 1 root root  434 Sep 21 11:02 classification_report.txt\n",
            "drwx------ 2 root root 4.0K Sep 21 11:02 figures\n",
            "-rw------- 1 root root  23K Sep 21 11:00 train_val_acc.png\n",
            "-rw------- 1 root root  23K Sep 21 11:00 train_val_loss.png\n",
            "total 92K\n",
            "-rw------- 1 root root 28K Sep 21 11:02 confusion_matrix.png\n",
            "-rw------- 1 root root 65K Sep 21 11:02 gradcam_glioma.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, glob, cv2, yaml\n",
        "from tensorflow.keras.models import load_model\n",
        "from src.data.generator import get_generators\n",
        "cfg = yaml.safe_load(open(\"config.yaml\"))\n",
        "model = load_model(os.path.join(cfg['paths']['models_dir'],'best_model.h5'))\n",
        "_, _, test_gen = get_generators(16)\n",
        "probs = model.predict(test_gen, verbose=0)\n",
        "pred = probs.argmax(1); true = test_gen.classes\n",
        "idx_to_name = {v:k for k,v in test_gen.class_indices.items()}\n",
        "mis_idx = np.where(pred != true)[0][:36]\n",
        "outdir = os.path.join(cfg['paths']['reports_dir'],'figures'); os.makedirs(outdir, exist_ok=True)\n",
        "# Save small grid of misclassifications\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12,12))\n",
        "for i,k in enumerate(mis_idx[:36]):\n",
        "    img_path = test_gen.filepaths[k]\n",
        "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(6,6,i+1); plt.imshow(img); plt.axis('off')\n",
        "    plt.title(f\"T:{idx_to_name[true[k]]}\\nP:{idx_to_name[pred[k]]}\", fontsize=8)\n",
        "plt.tight_layout(); plt.savefig(os.path.join(outdir,\"misclassified_grid.png\")); plt.close()\n",
        "print(\"Saved misclassified_grid.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpCrmfWe1OTB",
        "outputId": "774b5df5-a010-436c-9eb3-90b4901bd058"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4017 images belonging to 4 classes.\n",
            "Found 503 images belonging to 4 classes.\n",
            "Found 503 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved misclassified_grid.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(open(\"/content/drive/MyDrive/BTP_colab/reports/classification_report.txt\").read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnjzLHbe8iGs",
        "outputId": "7c42c422-e940-47f1-f0c6-827fce2f8ade"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      glioma       0.83      0.78      0.81       162\n",
            "  meningioma       0.81      0.75      0.78       165\n",
            "    no_tumor       0.00      0.00      0.00         0\n",
            "   pituitary       0.85      0.97      0.91       176\n",
            "\n",
            "    accuracy                           0.83       503\n",
            "   macro avg       0.62      0.62      0.62       503\n",
            "weighted avg       0.83      0.83      0.83       503\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "test_imgs = []\n",
        "for c in [\"glioma\",\"meningioma\",\"pituitary\",\"no_tumor\"]:\n",
        "    test_imgs += glob.glob(f\"data/processed/test/{c}/*.jpg\")[:1]\n",
        "for p in test_imgs[:4]:\n",
        "    !python -m src.predict \"{p}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZI8mKOz8iJ8",
        "outputId": "6d2f9e1c-25ec-4f35-bb27-5602fc3f584c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-21 11:04:38.096142: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758452678.118030   17303 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758452678.124308   17303 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758452678.139646   17303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452678.139673   17303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452678.139676   17303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452678.139680   17303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "I0000 00:00:1758452682.149962   17303 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9732 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1758452686.997281   17340 service.cc:152] XLA service 0x7c56d8004ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1758452686.997318   17340 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1758452687.715131   17340 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1758452689.931185   17340 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: [['input_layer']]\n",
            "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
            "  warnings.warn(msg)\n",
            "{'predicted': 'no_tumor', 'confidence': 0.3717025816440582, 'saved': '/content/drive/MyDrive/BTP_colab/reports/figures/gradcam_no_tumor.png'}\n",
            "2025-09-21 11:04:53.793312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758452693.813116   17443 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758452693.819158   17443 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758452693.834072   17443 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452693.834096   17443 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452693.834100   17443 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452693.834104   17443 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "I0000 00:00:1758452698.267318   17443 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9732 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1758452702.849089   17481 service.cc:152] XLA service 0x7d3918005090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1758452702.849123   17481 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1758452703.558685   17481 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1758452705.768721   17481 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: [['input_layer']]\n",
            "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
            "  warnings.warn(msg)\n",
            "{'predicted': 'glioma', 'confidence': 0.6966472268104553, 'saved': '/content/drive/MyDrive/BTP_colab/reports/figures/gradcam_glioma.png'}\n",
            "2025-09-21 11:05:08.645134: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758452708.664699   17581 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758452708.670693   17581 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758452708.685626   17581 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452708.685653   17581 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452708.685657   17581 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758452708.685660   17581 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "I0000 00:00:1758452713.639085   17581 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9732 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1758452717.622953   17617 service.cc:152] XLA service 0x79cfdc003cd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1758452717.622988   17617 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1758452718.315004   17617 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1758452720.508725   17617 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: [['input_layer']]\n",
            "Received: inputs=Tensor(shape=(1, 224, 224, 3))\n",
            "  warnings.warn(msg)\n",
            "{'predicted': 'no_tumor', 'confidence': 0.9425679445266724, 'saved': '/content/drive/MyDrive/BTP_colab/reports/figures/gradcam_no_tumor.png'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readme = f\"\"\"\n",
        "# Brain Tumor Detection (ResNet50 + Grad-CAM)\n",
        "\n",
        "- Dataset: 4-class T1-CE Brain MRI (Glioma/Meningioma/Pituitary/No Tumor)\n",
        "- Image size: {yaml.safe_load(open('config.yaml'))['data']['img_size']}\n",
        "- Training: Transfer learning + fine-tuning (see training_log.csv)\n",
        "- Checkpoint: best_model.h5 (saved to Drive)\n",
        "- Metrics: See classification_report.txt, confusion_matrix.png\n",
        "- Explainability: See Grad-CAM overlays in reports/figures\n",
        "\n",
        "Run order (Colab):\n",
        "1) Preprocess: python -m src.data.preprocess\n",
        "2) Train: python -m src.train\n",
        "3) Evaluate: python -m src.evaluate\n",
        "4) Grad-CAM demo: python -m src.predict data/processed/test/<class>/<image>.jpg\n",
        "\"\"\"\n",
        "open(\"/content/drive/MyDrive/BTP_colab/README_colab.txt\",\"w\").write(readme)\n",
        "print(\"Wrote README_colab.txt to Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQHHYanX8iNV",
        "outputId": "9e8b4513-d675-463d-cbe0-4af895f46093"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote README_colab.txt to Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -qr /content/BTP_colab_export.zip /content/drive/MyDrive/BTP_colab\n",
        "\n",
        "# Download to local machine via browser\n",
        "from google.colab import files\n",
        "files.download('/content/BTP_colab_export.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KDQ5KPKs9Dnb",
        "outputId": "638e8c4c-b3c1-4a2d-bf53-e0b4b93cabdb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33360591-7a97-4ff7-a5b6-5a0731008e9d\", \"BTP_colab_export.zip\", 204893114)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}